{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INF310-2021-Prática6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Seção 1: Inicialização e informações da GPU"
      ],
      "metadata": {
        "id": "ZBw5ZpzB1Ux0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lDRpMdcz8-Is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5ec006-e48d-4830-9531-45c7315122d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/canesche/nvcc4jupyter.git\n",
            "  Cloning git://github.com/canesche/nvcc4jupyter.git to /tmp/pip-req-build-q13dr341\n",
            "  Running command git clone -q git://github.com/canesche/nvcc4jupyter.git /tmp/pip-req-build-q13dr341\n",
            "Building wheels for collected packages: ColabPlugin\n",
            "  Building wheel for ColabPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ColabPlugin: filename=ColabPlugin-blind-py3-none-any.whl size=12727 sha256=543f6a8e9681b2a68559dd0615d102b17365526c4ff6f2c9d975fa399d83692e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ee8q0_ps/wheels/97/a0/61/b9e5e1f61c5cfd624df291d57f6731a0f5832606b9ced448ef\n",
            "\u001b[33m  WARNING: Built wheel for ColabPlugin is invalid: Metadata 1.2 mandates PEP 440 version, but 'blind' is not\u001b[0m\n",
            "Failed to build ColabPlugin\n",
            "Installing collected packages: ColabPlugin\n",
            "    Running setup.py install for ColabPlugin ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: ColabPlugin was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed ColabPlugin-blind\n",
            "Cloning into 'nvcc4jupyter'...\n",
            "remote: Enumerating objects: 1147, done.\u001b[K\n",
            "remote: Counting objects: 100% (362/362), done.\u001b[K\n",
            "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
            "remote: Total 1147 (delta 100), reused 328 (delta 74), pack-reused 785\u001b[K\n",
            "Receiving objects: 100% (1147/1147), 35.71 MiB | 19.22 MiB/s, done.\n",
            "Resolving deltas: 100% (554/554), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+git://github.com/canesche/nvcc4jupyter.git\n",
        "!git clone https://github.com/canesche/nvcc4jupyter\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%gpu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(){\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "    printf(\"Using Device %d:         %s\\n\",     dev, deviceProp.name);\n",
        "    printf(\"Total global memory:     %u B\\n\",   deviceProp.totalGlobalMem);\n",
        "    printf(\"Threads per block:       %d\\n\",     deviceProp.maxThreadsPerBlock);\n",
        "    printf(\"Maximum Grid Size:       %d,%d,%d\\n\",deviceProp.maxGridSize[0],\n",
        "                                                deviceProp.maxGridSize[1],\n",
        "                                                deviceProp.maxGridSize[2]);\n",
        "    printf(\"Maximum block size:      %d,%d,%d\\n\",deviceProp.maxThreadsDim[0],\n",
        "                                                deviceProp.maxThreadsDim[1],\n",
        "                                                deviceProp.maxThreadsDim[2]);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "jNJcTqth9f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a06350-f6a9-4de1-ccb7-c141bc6f42c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device 0:         Tesla K80\n",
            "Total global memory:     3407020032 B\n",
            "Threads per block:       1024\n",
            "Maximum Grid Size:       2147483647,65535,65535\n",
            "Maximum block size:      1024,1024,64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seção 2: Atividade prática"
      ],
      "metadata": {
        "id": "Cf3ARXlS1nVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No jogo campo minado, diversas bombas são distribuídas sobre um campo representado por uma matriz, e cada célula sem bomba guarda o número de bombas existentes nas 8 células ao seu redor. Dessa forma, o campo abaixo à esquerda,\n",
        "onde cada bomba é representada por um *, pode ser armazenado pela matriz de inteiros mostrada à direita, onde cada bomba é representada por um 9. \n",
        "```\n",
        "1 * 2 2 *                1 9 2 2 9 \n",
        "2 4 * 3 1                2 4 9 3 1\n",
        "* 5 * 2                  9 5 9 2 0\n",
        "* * 3 1                  9 9 3 1 0\n",
        "3 * 2                    3 9 2 0 0\n",
        "```\n",
        "Faça um programa que distribui de forma aleatória um número de bombas e, em seguida, utiliza a GPU para calcular de forma paralela o número de bombas próximas a cada célula sem bomba.\n",
        "\n",
        "Depois que estiver certo que seu kernel funciona, implemente também uma versão sequencial para fazer o mesma cálculo e insira marcadores de tempo para calcular e exibir o tempo gasto em cada uma das duas abordagens. Aumente o tamanho do campo progressivamente para valores muito grandes (ex: 10000x10000) e perceba que o tempo de cálculo na versão paralela tem um aumento relativamente baixo em relação à versão sequencial."
      ],
      "metadata": {
        "id": "nroptPp41wrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%nvprof\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdexcept>\n",
        "#include <assert.h>\n",
        "#include <unistd.h>\n",
        "#include <chrono>\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "//#define DEBUG\n",
        "\n",
        "/* A função CHECK a seguir pode ser utilizada caso seja necessário identificar\n",
        "erros em chamadas da biblioteca CUDA. Exemplo: \n",
        "CHECK(cudaMalloc((void**)&x,size));\n",
        "*/\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "void distribuiBombas(int8_t *a, int linhas, int colunas, int num){\n",
        "    if (num > linhas*colunas)\n",
        "        throw std::invalid_argument(\"Número de bombas extrapolou o máximo possível.\");\n",
        "\n",
        "    for (int i=0; i<linhas; ++i)\n",
        "        for (int j=0; j<colunas; ++j)\n",
        "            a[i*colunas+j]=0;\n",
        "\n",
        "    int lin, col;\n",
        "    for (int i=0; i<num; ++i) {\n",
        "        lin=rand()%linhas;\n",
        "        col=rand()%colunas;\n",
        "        while (a[lin*colunas+col] == 9) {\n",
        "            lin=rand()%linhas;\n",
        "            col=rand()%colunas;\n",
        "        }\n",
        "        a[lin*colunas+col]=9;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void imprimeMatriz(int8_t *a, int linhas, int colunas ){\n",
        "    int v;\n",
        "    for (int i=0; i<linhas; ++i) {\n",
        "        for (int j=0; j<colunas; ++j) {\n",
        "            v=a[i*colunas+j];\n",
        "            if (v==9) printf(\"* \");\n",
        "            //else if (v==0) printf(\"  \");\n",
        "            //else printf(\"%d \",v);\n",
        "            else printf(\"%d \",v);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void geraVizinhos(int8_t *a, int8_t *b, int linhas, int colunas){\n",
        "    int i = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int j = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    int pos = i*colunas+j;\n",
        "\n",
        "    if (a[pos] == 9) b[pos] = 9;\n",
        "\n",
        "    //testa se a posicao é valida, podem haver threads tentando acessar posições fora da matriz\n",
        "    if(pos > linhas*colunas || i>= linhas || j>= colunas || a[pos] == 9) return;\n",
        "\n",
        "    //lista de vizinhos, como todas as posições a serem testadas\n",
        "    int vizinhos[8][2] = {{0,1},{1,1}, {-1,1}, {-1,0}, {1,0}, {0,-1},{1,-1}, {-1,-1}};\n",
        "    int auxI = 0, auxJ = 0;\n",
        "\n",
        "    //cada thread testa seus 8 vizinhos\n",
        "    for(int k = 0; k<8; k++){\n",
        "\n",
        "        //move para o vizinho\n",
        "        auxI = i+vizinhos[k][0];\n",
        "        auxJ = j+vizinhos[k][1];\n",
        "\n",
        "      if(auxI >= 0 and auxI< linhas && auxJ >= 0 && auxJ < colunas && a[auxI*colunas+auxJ] == 9)\n",
        "        ++b[pos];\n",
        "    }\n",
        "}\n",
        "\n",
        "//mesma lógica da gpu, porém sequencial\n",
        "void vizinhosSeq(int8_t* m, int linhas, int colunas) {\n",
        "  int vizinhos[][2] = {{0,1},{1,1}, {-1,1}, {-1,0}, {1,0}, {0,-1},{1,-1}, {-1,-1}};\n",
        "  int auxX = 0, auxY = 0;\n",
        "\n",
        "  for(int i = 0; i < linhas; i++){   \n",
        "    for(int j = 0; j < colunas; j++){\n",
        "        if(m[i*colunas+j] == 9) continue;\n",
        "\n",
        "        for(int k = 0; k < 8; k++) {\n",
        "          auxX = i+vizinhos[k][0];\n",
        "          auxY = j+vizinhos[k][1];\n",
        "\n",
        "          if(auxX >=0 && auxX < linhas && auxY >=0 && auxY < colunas && m[auxX*colunas + auxY] == 9)\n",
        "            m[i*colunas + j] ++;\n",
        "        }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "//inicializa uma matriz com todas as posições zeradas\n",
        "void inicializa(int8_t *a, int linhas, int colunas){\n",
        "    for (int i=0; i<linhas; ++i)\n",
        "        for (int j=0; j<colunas; ++j)\n",
        "            a[i*colunas+j]=0;\n",
        "}\n",
        "\n",
        "\n",
        "//confere se duas matrizes são iguais\n",
        "void confere(int8_t *a, int8_t *b, int linhas, int colunas){\n",
        "    for (int i=0; i<linhas; ++i)\n",
        "        for (int j=0; j<colunas; ++j)\n",
        "            if(a[i*colunas+j]!=b[i*colunas+j]){ printf(\"Erro nas posições %d %d\\n\",i,j); return;}\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    //não estava conseguindo medir o tempo com valores mais altos, dava erro no buffer size ??\n",
        "    int linhas = 8000, colunas=8000; //64*10^6 posições\n",
        "    int numBombas = 40000000;         //4*10^6 bombas => uma a cada 8 posições tinha bomba \n",
        "    int8_t *h_A, *h_B;\n",
        "    int8_t *d_A, *d_B;\n",
        "\n",
        "\n",
        "    int size = linhas*colunas*sizeof(int8_t);\n",
        "    h_A = (int8_t*)malloc(size);\n",
        "    h_B = (int8_t*)malloc(size);\n",
        "\n",
        "    inicializa(h_A,linhas,colunas);\n",
        "    inicializa(h_B,linhas,colunas);\n",
        "\n",
        "\n",
        "\n",
        "    distribuiBombas(h_A,linhas,colunas,numBombas);\n",
        "\n",
        "    cudaMalloc((void **) &d_A, size);\n",
        "    cudaMalloc((void **) &d_B, size);\n",
        "\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 grid (ceil(colunas*1.0/BLOCK_SIZE),ceil(linhas*1.0/BLOCK_SIZE),1);\n",
        "    dim3 block (BLOCK_SIZE,BLOCK_SIZE,1);\n",
        "    geraVizinhos<<<grid,block>>>(d_A,d_B,linhas,colunas);\n",
        "    \n",
        "\n",
        "\n",
        "    //cudaDeviceReset();\n",
        "\n",
        "    cudaMemcpy(h_B, d_B, size, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    //printf(\"%d \\n\",h_A[0]);\n",
        "\n",
        "    auto start = chrono::system_clock::now();\n",
        "    vizinhosSeq(h_A,linhas,colunas);\n",
        "    auto end = chrono::system_clock::now();\n",
        "    chrono::duration<double> time = end - start;\n",
        "\n",
        "    #ifdef DEBUG\n",
        "    {\n",
        "        imprimeMatriz(h_A,linhas,colunas);\n",
        "        imprimeMatriz(h_B,linhas,colunas);\n",
        "    \n",
        "        confere(h_B,h_A,linhas,colunas);\n",
        "    }\n",
        "    #endif\n",
        "    \n",
        "    printf(\"A execução na CPU levou %fs.\\n\",time.count());\n",
        "\n",
        "\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    return 0;    \n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "rWYIpRJteQ4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d354ba5b-5477-4e49-93fd-51d0d5687d44"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==3477== NVPROF is profiling process 3477, command: /content/code.out\n",
            "==3477== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "A execução na CPU levou 2.676481s.\n",
            "==3477== Profiling application: /content/code.out\n",
            "==3477== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   60.64%  27.081ms         1  27.081ms  27.081ms  27.081ms  geraVizinhos(char*, char*, int, int)\n",
            "                   20.48%  9.1466ms         1  9.1466ms  9.1466ms  9.1466ms  [CUDA memcpy HtoD]\n",
            "                   18.88%  8.4291ms         1  8.4291ms  8.4291ms  8.4291ms  [CUDA memcpy DtoH]\n",
            "      API calls:   78.14%  193.59ms         2  96.797ms  223.59us  193.37ms  cudaMalloc\n",
            "                   18.15%  44.960ms         2  22.480ms  9.2606ms  35.699ms  cudaMemcpy\n",
            "                    3.40%  8.4275ms         2  4.2137ms  258.91us  8.1686ms  cudaFree\n",
            "                    0.21%  513.20us         1  513.20us  513.20us  513.20us  cuDeviceTotalMem\n",
            "                    0.08%  191.04us       101  1.8910us     145ns  84.661us  cuDeviceGetAttribute\n",
            "                    0.01%  36.262us         1  36.262us  36.262us  36.262us  cuDeviceGetName\n",
            "                    0.01%  35.273us         1  35.273us  35.273us  35.273us  cudaLaunchKernel\n",
            "                    0.00%  6.9600us         1  6.9600us  6.9600us  6.9600us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7240us         2     862ns     310ns  1.4140us  cuDeviceGet\n",
            "                    0.00%  1.7180us         3     572ns     203ns     968ns  cuDeviceGetCount\n",
            "                    0.00%     314ns         1     314ns     314ns     314ns  cuDeviceGetUuid\n",
            "\n"
          ]
        }
      ]
    }
  ]
}