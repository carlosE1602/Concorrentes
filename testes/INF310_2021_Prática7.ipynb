{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INF310-2021-Prática7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbPApI7pbK7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf81722-a1d6-4d7e-833b-3d1e4ddd704f"
      },
      "source": [
        "!pip install git+https://github.com/canesche/nvcc4jupyter.git\n",
        "!git clone https://github.com/canesche/nvcc4jupyter\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/canesche/nvcc4jupyter.git\n",
            "  Cloning https://github.com/canesche/nvcc4jupyter.git to /tmp/pip-req-build-vwjxhur3\n",
            "  Running command git clone -q https://github.com/canesche/nvcc4jupyter.git /tmp/pip-req-build-vwjxhur3\n",
            "Building wheels for collected packages: ColabPlugin\n",
            "  Building wheel for ColabPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ColabPlugin: filename=ColabPlugin-blind-py3-none-any.whl size=12727 sha256=28e3d5d526d4f33c9f80836abb2fea6fc4bbcb9808270f161e33d21f33b9e3b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yy_052cz/wheels/06/76/5f/88825d3256ab9fe9e4386e23ad33a2c41a2e4dc94f0addff44\n",
            "\u001b[33m  WARNING: Built wheel for ColabPlugin is invalid: Metadata 1.2 mandates PEP 440 version, but 'blind' is not\u001b[0m\n",
            "Failed to build ColabPlugin\n",
            "Installing collected packages: ColabPlugin\n",
            "    Running setup.py install for ColabPlugin ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: ColabPlugin was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed ColabPlugin-blind\n",
            "Cloning into 'nvcc4jupyter'...\n",
            "remote: Enumerating objects: 1147, done.\u001b[K\n",
            "remote: Counting objects: 100% (362/362), done.\u001b[K\n",
            "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
            "remote: Total 1147 (delta 100), reused 328 (delta 74), pack-reused 785\u001b[K\n",
            "Receiving objects: 100% (1147/1147), 35.71 MiB | 19.36 MiB/s, done.\n",
            "Resolving deltas: 100% (554/554), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp2gpshU9U1m"
      },
      "source": [
        "\n",
        "Considere que desejamos gerar um array B através de um array A de mesmo tamanho, de modo que, cada elemento `B[i]` é dado pela soma do elemento `A[i]` mais os `r` elementos anteriores à posição `i` em A mais os `r` elementos posteriores, ou seja:\n",
        "```\n",
        "for(j=i-r; j<=i+r; j++)\n",
        "    B[i]+=A[j]\n",
        "```\n",
        "O código dado a seguir já faz o cálculo do array B (armazenado em `bHost`) de forma sequencial. Escreva um kernel CUDA, bem como todo o restante do código necessário para executá-lo, de modo a permitir o cálculo de B de forma paralela.\n",
        "\n",
        "As posições inválidas no início e final do array A devem ser simplesmente descartadas durante a soma, ou seja, para cálculo de `B[10]` com `r=32`, o resultado será a soma dos elementos de `A[0]` até `A[42]`.\n",
        "\n",
        "Se atente para os seguinte requisitos:\n",
        "* O cálculo dos elementos de B deve ser realizado de forma paralela;\n",
        "* A memória compartilhada da GPU deve ser utilizada de forma a deixar a operação mais eficiente;\n",
        "* O código deve tratar corretamente arrays grandes divididos em mais de um bloco.\n",
        "\n",
        "Dicas:\n",
        "* O código abaixo utiliza a constante `RANGE` para definir o valor de `r` e a constante `BLOCKSIZE` para definir o tamanho de cada bloco do grid;\n",
        "* Por simplicidade, você pode considerar que o tamanho do array A será sempre múltiplo de `BLOCKSIZE`;\n",
        "* Considere também que o tamanho de `r` será no máximo igual à metade de `BLOCKSIZE`.\n",
        "* A estratégia utilizada pela versão sequencial de testar cada posição (para descobrir se é válida) não é ótima. Muitas comparações desnecessárias são realizadas ao calcular as posições intermediárias. Na versão paralela, é melhor preecher as posições inválidas com o valor 0 (zero) ao copiar os dados para a memória compartilhada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7rUJaOP0hfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7e3ee9-9e1f-43a3-c2f4-d1dacaa00490"
      },
      "source": [
        "%%gpu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "\n",
        "#define BLOCKSIZE 1024   //threads por bloco\n",
        "#define RANGE 256       //deslocamento utilizado para cálculo de B\n",
        "\n",
        "void initArray(int *a, int n) {\n",
        "    for (int i =0; i<n; ++i) \n",
        "        a[i]=i;\n",
        "}\n",
        "\n",
        "void printArray(int *a, int n) {\n",
        "    int maxPrint=20;\n",
        "    for (int i =0; i<(n>maxPrint ? maxPrint : n); ++i) \n",
        "        printf(\"%3d \",a[i]);\n",
        "    if (n>maxPrint) printf(\"... (array truncado)\");\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "bool checkArray(int *a, int *b, int n) {\n",
        "    for (int i =0; i<n; ++i) \n",
        "        if (a[i]!=b[i])\n",
        "            return false;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "void execHost(int *A, int n, int *B) {\n",
        "    for(int i=0; i<n; i++) {\n",
        "        B[i]=0;\n",
        "        for(int j=i-RANGE; j<=i+RANGE; j++)  \n",
        "            if(j >= 0 && j<n)\n",
        "                B[i]+=A[j];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void execDevice(int *A, int n, int *B){\n",
        "      const int N = RANGE*2 + BLOCKSIZE; //a memoria auxiliar deve ter o tamanho do bloco\n",
        "                                         // mais os espaços para os dados do RANGE*2(atras e na frente)\n",
        "      __shared__ int s_A[N];\n",
        "\n",
        "      int tId = blockIdx.x *blockDim.x + threadIdx.x; //id da thread no vetor a\n",
        "      int tx = threadIdx.x; //id da thread no bloco\n",
        "\n",
        "      s_A[tx+RANGE] = A[tId];   //posições que não são extremos podem ser carregadas direto na memoria\n",
        "\n",
        "      if(tx == 0){  //se é a primeira thread do bloco as posições a esquerda devem ser preenchidas\n",
        "          for(int i = 0;i<RANGE+1;i++){ \n",
        "              if(tId-i < 0)    //se não é uma posição válida, colocar 0 na memória\n",
        "                s_A[tx-i + RANGE] = 0;\n",
        "              else s_A[tx-i + RANGE] = A[tId-i];\n",
        "          }\n",
        "      }\n",
        "      if(tx == BLOCKSIZE -1){ // se for a ultima thread do bloco as posições a direita devem ser preenchidas com 0\n",
        "          for(int j = 0;j< RANGE+1;j++){\n",
        "              if(tId+j >= n)       //se não é uma posição válida, colocar 0 na memória\n",
        "                  s_A[tx+j + RANGE] = 0;\n",
        "              else s_A[tx+j + RANGE] = A[tId + j];\n",
        "          }\n",
        "      }\n",
        "\n",
        "      __syncthreads();\n",
        "\n",
        "\n",
        "      int soma = 0; //variavel auxiliar, evita atualizar direto na memoria global\n",
        "\n",
        "      for(int i = tx;i<= tx+2*RANGE;i++){\n",
        "          soma += s_A[i];\n",
        "      }\n",
        "      \n",
        "      B[tId] = soma;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int size=1<<20;             //tamanho dos arrays A e B\n",
        "    int dsize=size*sizeof(int); //tamanho dos dados\n",
        "    int *a;\n",
        "    int *b;                     //array B a ser calculado na GPU\n",
        "    int *bHost;                 //array B calculado na CPU\n",
        "    \n",
        "    int *d_A;\n",
        "    int *d_B;\n",
        "\n",
        "    a=(int*)malloc(dsize);\n",
        "    b=(int*)malloc(dsize);\n",
        "    bHost=(int*)malloc(dsize);\n",
        "\n",
        "    // Aloca os vetores que serão usados no calc\n",
        "    cudaMalloc((void **) &d_A, dsize);\n",
        "    cudaMalloc((void **) &d_B, dsize);\n",
        "\n",
        "    initArray(a,size);\n",
        "    printf(\"    A: \");\n",
        "    printArray(a,size);\n",
        "\n",
        "    // Faz uma cópia de A que será passado para a função\n",
        "    cudaMemcpy(d_A, a, dsize, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 grid (ceil(size*1.0/BLOCKSIZE), 1, 1);\n",
        "    dim3 block (BLOCKSIZE, 1, 1);\n",
        "\n",
        "    printf(\"B-GPU: \");\n",
        "    execDevice <<<grid, block>>>(d_A, size, d_B);\n",
        "\n",
        "    // copia de volta para um B\n",
        "    cudaMemcpy(b, d_B, dsize, cudaMemcpyDeviceToHost);\n",
        "    printArray(b,size);\n",
        "\n",
        "    printf(\"B-CPU: \");\n",
        "    execHost(a, size, bHost);\n",
        "    printArray(bHost,size);\n",
        "\n",
        "    if (checkArray(b,bHost,size))\n",
        "        printf(\"Resultados iguais\\n\");\n",
        "    else\n",
        "        printf(\"Resultados diferentes\\n\");\n",
        "\n",
        "    free(bHost);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A:   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 ... (array truncado)\n",
            "B-GPU: 32896 33153 33411 33670 33930 34191 34453 34716 34980 35245 35511 35778 36046 36315 36585 36856 37128 37401 37675 37950 ... (array truncado)\n",
            "B-CPU: 32896 33153 33411 33670 33930 34191 34453 34716 34980 35245 35511 35778 36046 36315 36585 36856 37128 37401 37675 37950 ... (array truncado)\n",
            "Resultados iguais\n",
            "\n"
          ]
        }
      ]
    }
  ]
}